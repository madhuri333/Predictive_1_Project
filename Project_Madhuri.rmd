---
title: "Project - MSiA 401 Predictive Analytics-1"
author: "Madhuri Gupta"
date: "November 20, 2016"
output: pdf_document
---

### Reading and Cleaning Data 

I read the data from "donation data" into "donation" data frame.   

```{r, echo=TRUE}
# Read Data and load first few rows
donate <- read.csv("donation data.csv")
dmef <-  read.csv("dmef1code.csv")
#Removing type=* from CODETYPE
dmef <- dmef[!dmef$CODETYPE=="*", ]
#Re-factoring keeps only 5 levels
dmef$CODETYPE <- factor(dmef$CODETYPE)
#Make missing CNDOL2/3 = 0
donate[is.na(donate$CNDOL2), "CNDOL2"] <- 0
donate[is.na(donate$CNDOL3), "CNDOL3"] <- 0
```
  
**Replacing codes for CNCOD, SLCOD**  
  
```{r, echo=TRUE}
code <- function(x){
    x <- as.data.frame(x)
    names(x) <- "CODE"
    temp <- join(x, dmef, by = "CODE")
    temp <- temp$CODETYPE
    return(temp)
}
library(plyr)
donate$CNCOD1 <- code(donate$CNCOD1)
donate$CNCOD2 <- code(donate$CNCOD2)
donate$CNCOD3 <- code(donate$CNCOD3)
donate$SLCOD1 <- code(donate$SLCOD1)
donate$SLCOD2 <- code(donate$SLCOD2)
donate$SLCOD3 <- code(donate$SLCOD3)

suppressMessages(library(Amelia))
#missmap(donate)
#saved the image as mismap.pdf to be attached with report
```
  
  
It can be observed that data related to $2^{nd}$ and $3^{rd}$ contribution codes has the most missing values so these variables will not be considered further for inclusion in predictors for the model. Furthermore, the variables "CNDAT" and "CNMON" has perfect negative correlation so only one of them ("CNMON") will be considered. Also variable "ID", "STATCODE" shall not be used in predictive model.      
  
    
```{r, echo=TRUE}
#Looking at the correlation between numeric variables being considered (incl TARGET)
cor_mat <- round(cor(donate[, c(1,2,3,4,11,12,13,17,20,23,24)]),3)
test <- cor_mat>0.7
```
  
  
It can be observed that there is high correlation (>0.8) between (Largest, Latest contribution) and (Times contributed, Months since first contribution). We would choose to keep Latest contribution and Times contributed for the analysis.   
   
   
```{r, echo=T}
#Removing least useful variables based on above analysis
donate_trim <- donate[,c(1,2,4,5,11,12,13,14,15,17,19,20,24)]

```    
    
    
**Divide data into training and test dataset**  
  
  
```{r, echo=T}
n <- 3
test_index <- seq(n, nrow(donate_trim), by = n)
train <- donate_trim[-test_index, ]
test <- donate_trim[test_index, ]
test_complete <- test[complete.cases(test), ] 
train$DON_BIN <- as.numeric(train$TARGDOL>0)
train_complete <- train[complete.cases(train), ]
```     
    
    
  
```{r, echo=T}
library(caret)
ctrl <- trainControl(method = "repeatedcv", number = 10, savePredictions = F)

mod_fit1 <- train(DON_BIN ~ .-TARGDOL ,  data=train_complete, method="glm", family="binomial",
                 trControl = ctrl)


fit1 <- glm(form = DON_BIN~.-TARGDOL, family = "binomial", data = train)
summary(fit1)
newdata <- train
predicted_DON_BIN <- predict(fit1, newdata, type = "response") 

p <- seq(0.1, 0.9, by = 0.1)
cost <-  function(p_value, c1, c2){
  tab <- table(mod_fit1$finalModel$y, mod_fit1$finalModel$fitted.values > p_value)
  c <- c1*tab[1,2] + c2*tab[2,1]
  precision <- tab[2,2]/sum(tab[,2])
  recal <- tab[2,2]/sum(tab[2,])
  ccr <- (sum(diag(tab))/sum(tab))
  f <- 2*precision*recal/(precision+recal)
  cat("P:", precision,"R:", recal,"CCR:",ccr,"F:",f)
  return(c)
}

# cost data frame:
cost_df <- data.frame("p_cutoff"=p)
cost_df$Cost_0.2 <- sapply(p, function(x) cost(x,1,5))
# To be able to compare the costs I choose ratio such that their sum is 6 so c1=c2=3 
cost_df$Cost_1 <- sapply(p, function(x) cost(x,3,3))
cost_df$Cost_5 <- sapply(p, function(x) cost(x,5,1))

# plotting against p*

plot(cost_df$p_cutoff, cost_df$Cost_5, xlab = "p*", ylab = "Costs", type = "l", col="blue")
lines(cost_df$p_cutoff, cost_df$Cost_1, type = "l", col="green")
lines(cost_df$p_cutoff, cost_df$Cost_0.2, type = "l", col="red")
legend("top", c("ratio 0.2","ratio 1", "ratio 5"), col=c("red","green","blue"), lty=1, cex=0.9)

# taking p* at 0.3 for maximizing F score
#This aligns with the objective that a 
tab <- table(mod_fit1$finalModel$y, mod_fit1$finalModel$fitted.values > 0.3)
ccr <- sum(diag(tab))/sum(tab)
precision <- tab[2,2]/sum(tab[,2])
recal <- tab[2,2]/sum(tab[2,])

library(pROC)
plot.roc(train_complete$DON_BIN, fit1$fitted.values, xlab="1-Specificity")

test_pred <- predict(fit1, newdata = test_complete, type = "response")
tab1 <- table(test_don_bin, test_pred > 0.3)
ccr <- sum(diag(tab1))/sum(tab1)
precision <- tab1[2,2]/sum(tab1[,2])
recal <- tab1[2,2]/sum(tab1[2,])


```         
    
    
    
```{r, echo=T}    
# Multiple Regression Data
mlr1 <- lm(data = subset(donate, donate$TARGDOL>0), formula = TARGDOL~.-ID )
summary(mlr1)
mlr2 <- lm(data = subset(donate_trim, donate_trim$TARGDOL>0), formula = TARGDOL~. )
summary(mlr2)



```
   
   
   
   
   
   
   
**Thank you**